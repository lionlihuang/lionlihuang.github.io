<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>煌煌的博客</title>
    <link>http://lionlihuang.github.io/</link>
    <description>Recent content on 煌煌的博客</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-Hans</language>
    <lastBuildDate>Thu, 28 May 2020 14:44:39 +0800</lastBuildDate>
    
	<atom:link href="http://lionlihuang.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Collection体系</title>
      <link>http://lionlihuang.github.io/doc/collection%E4%BD%93%E7%B3%BB/</link>
      <pubDate>Thu, 28 May 2020 14:44:39 +0800</pubDate>
      
      <guid>http://lionlihuang.github.io/doc/collection%E4%BD%93%E7%B3%BB/</guid>
      <description>Collection体系的常用类及其背后的数据结构 List ArrayList： 背后是一个动态数组，有序插入元素，可以根据下标取得对应元素，检索元素为线性查找，效率较低。当容量不足时会自动扩容，每次新建一个新的List，大小为原来的1.5倍，再将所有元素拷贝到新的List中去。 LinkedList： 背后是一个链表结构，有序插入元素，可以根据下标取得对应元素， 检索时从头部或者尾部不断向下标靠拢，所以头部和尾部的查找效率高，中间低。 Set HashSet： 计算出元素的哈希值，哈希值相同的元素放在同一个哈希桶里，每个哈希桶里维护一个链表。插入的元素是无序的且不允许出现重复元素，查找效率高。但当发生哈希碰撞时，整个结构退化为链表会导致性能急剧下降。 LinkedHashSet： 不同于HashSet，前面的数据结构为链表，所以是有序的，其他几乎一样。 TreeSet： 前面的数据结构为二叉树，可以对插入的元素进行排序。检索快，时间复杂度降为对数级。 Map HashMap： 实质上和HashSet一样，不过可以存储键（Key）到值（Value）的映射。JDK1.8之后当链表节点大于7时会裂变为红黑树。 TreeMap： 可以排序的HashMap。
Collection体系的常用类及其背后的数据结构对比 ArrayList源码阅读 成员变量 构造函数 添加元素方法 插入 添加集合方法 移除元素方法 删除元素 查询 从前往后查找第一个出现的元素 集合运算
ArrayList是如何扩容的？ 写过的项目到现在基本上面向业务域查询返回大列表都是使用ArrayList来存储业务数据的。
定义：ArrayList是List接口的可变数组的实现。实现了所有的可选列表的操作并允许包括null在内的所有元素。除了实现List接口外，此类还提供一些方法来操作内部用来存储列表的数组的大小。
每个ArrayList实例都有一个容量，该容量是指来存储列表元素的数组的大小，该容量至少等于列表数组的大小，随着ArrayList的不断添加元素，其容量也在自动增长，自动增长会将原来数组的元素向新的数组进行copy。因此，如果根据业务场景来提前预判数据量的大小。可在构造ArrayList时指定其容量。在添加大量元素前，应用程序可以使用ensureCapacity操作来增加ArrayList实例的容量，这样就可以减少递增式再分配数量的操作。
注意：我们都知道ArrayList不是线程安全的，如果存在多线程访问ArrayList实例的场景，其中一个线程要在改变ArrayList列表结构之前，需要先对它这个操作保持线程同步。 ArrayList是采取延迟分配对象数组大小空间的，当第一次添加元素时才会分配10个对象空间，当添加第11个元素的时候，会扩容1.5倍，当添加到16个元素的时候扩容为15*1.5=22，以此类推。
HashMap源码阅读 构造方法一共重载了四个，主要初始化了三个参数：
initialCapacity 初始容量（默认16）： hashMap底层由数组实现+链表（或红黑树）实现，但是还是从数组开始，所以当储存的数据越来越多的时候，就必须进行扩容操作，如果在知道需要储存数据大小的情况下，指定合适的初始容量，可以避免不必要的扩容操作，提升效率 threshold 阈值：hashMap所能容纳的最大价值对数量，如果超过则需要扩容，计算方式：threshold=initialCapacity*loadFactor（构造方法中直接通过tableSizeFor(initialCapacity)方法进行了赋值，主要原因是在构造方法中，数组table并没有初始化，put方法中进行初始化，同时put方法中也会对threshold进行重新赋值，这个会在后面的源码中进行分析） loadFactor 加载因子（默认0.75）：当负载因子较大时，去给table数组扩容的可能性就会少，所以相对占用内存较少（空间上较少），但是每条entry链上的元素会相对较多，查询的时间也会增长（时间上较多）。反之就是，负载因子较少的时候，给table数组扩容的可能性就高，那么内存空间占用就多，但是entry链上的元素就会相对较少，查出的时间也会减少。所以才有了负载因子是时间和空间上的一种折中的说法。所以设置负载因子的时候要考虑自己追求的是时间还是空间上的少。（一般情况下不需要设置，系统给的默认值已经比较适合了）
我们最常使用的是无参构造，在这个构造方法里面仅仅设置了加载因子为默认值，其他两个参数会在resize方法里面进行初始化，在这里知道这个结论就可以了，下面会在源码里面进行分析； 另外一个带有两个参数的构造方法，里面对初始容量和阈值进行了初始化，对阈值的初始化方法为 tableSizeFor(int cap) put方法 table尚未初始化 get方法，查找 取模运算 (n - 1) &amp;amp; hash remove方法，删除 其他源码 到这里，hashMap的源码基本就解析完成了，其余的方法和源码逻辑相对非常简单，大部分还是使用上述代码来实现的，例如containsKey（jey），就是使用get方法中的getNode（）来判断的，由于篇幅原因就不一一介绍。 另外，中间有很部分不影响逻辑理解的代码被一笔带过，比如 红黑树的转化，查找，删除等操作，有兴趣的可以自己进行学习，不过还有一些其他的特性需要提醒一下 最后总结一下：
HashMap 底层数据结构在JDK1.7之前是由数组+链表组成的，1.8之后又加入了红黑树；链表长度小于8的时候，发生Hash冲突后会增加链表的长度，当链表长度大于8的时候，会先判读数组的容量，如果容量小于64会先扩容（原因是数组容量越小，越容易发生碰撞，因此当容量过小的时候，首先要考虑的是扩容），如果容量大于64，则会将链表转化成红黑树以提升效率 hashMap 的容量是2的n次幂，无论在初始化的时候传入的初始容量是多少，最终都会转化成2的n次幂，这样做的原因是为了在取模运算的时候可以使用&amp;amp;运算符，而不是%取余，可以极大的提上效率，同时也降低hash冲突 HashMap是非线程安全的，在多线程的操作下会存在异常情况（如形成闭环（1.7），1.8已修复闭环问题，但仍不安全），可以使用HashTable或者ConcurrentHashMap进行代替</description>
    </item>
    
    <item>
      <title>Collection体系</title>
      <link>http://lionlihuang.github.io/posts/collection%E4%BD%93%E7%B3%BB/</link>
      <pubDate>Thu, 28 May 2020 14:11:20 +0800</pubDate>
      
      <guid>http://lionlihuang.github.io/posts/collection%E4%BD%93%E7%B3%BB/</guid>
      <description>Collection体系的常用类及其背后的数据结构 List ArrayList： 背后是一个动态数组，有序插入元素，可以根据下标取得对应元素，检索元素为线性查找，效率较低。当容量不足时会自动扩容，每次新建一个新的List，大小为原来的1.5倍，再将所有元素拷贝到新的List中去。 LinkedList： 背后是一个链表结构，有序插入元素，可以根据下标取得对应元素， 检索时从头部或者尾部不断向下标靠拢，所以头部和尾部的查找效率高，中间低。 Set HashSet： 计算出元素的哈希值，哈希值相同的元素放在同一个哈希桶里，每个哈希桶里维护一个链表。插入的元素是无序的且不允许出现重复元素，查找效率高。但当发生哈希碰撞时，整个结构退化为链表会导致性能急剧下降。 LinkedHashSet： 不同于HashSet，前面的数据结构为链表，所以是有序的，其他几乎一样。 TreeSet： 前面的数据结构为二叉树，可以对插入的元素进行排序。检索快，时间复杂度降为对数级。 Map HashMap： 实质上和HashSet一样，不过可以存储键（Key）到值（Value）的映射。JDK1.8之后当链表节点大于7时会裂变为红黑树。 TreeMap： 可以排序的HashMap。
Collection体系的常用类及其背后的数据结构对比 ArrayList源码阅读 成员变量 构造函数 添加元素方法 插入 添加集合方法 移除元素方法 删除元素 查询 从前往后查找第一个出现的元素 集合运算
ArrayList是如何扩容的？ 写过的项目到现在基本上面向业务域查询返回大列表都是使用ArrayList来存储业务数据的。
定义：ArrayList是List接口的可变数组的实现。实现了所有的可选列表的操作并允许包括null在内的所有元素。除了实现List接口外，此类还提供一些方法来操作内部用来存储列表的数组的大小。
每个ArrayList实例都有一个容量，该容量是指来存储列表元素的数组的大小，该容量至少等于列表数组的大小，随着ArrayList的不断添加元素，其容量也在自动增长，自动增长会将原来数组的元素向新的数组进行copy。因此，如果根据业务场景来提前预判数据量的大小。可在构造ArrayList时指定其容量。在添加大量元素前，应用程序可以使用ensureCapacity操作来增加ArrayList实例的容量，这样就可以减少递增式再分配数量的操作。
注意：我们都知道ArrayList不是线程安全的，如果存在多线程访问ArrayList实例的场景，其中一个线程要在改变ArrayList列表结构之前，需要先对它这个操作保持线程同步。 ArrayList是采取延迟分配对象数组大小空间的，当第一次添加元素时才会分配10个对象空间，当添加第11个元素的时候，会扩容1.5倍，当添加到16个元素的时候扩容为15*1.5=22，以此类推。
HashMap源码阅读 构造方法一共重载了四个，主要初始化了三个参数：
initialCapacity 初始容量（默认16）： hashMap底层由数组实现+链表（或红黑树）实现，但是还是从数组开始，所以当储存的数据越来越多的时候，就必须进行扩容操作，如果在知道需要储存数据大小的情况下，指定合适的初始容量，可以避免不必要的扩容操作，提升效率 threshold 阈值：hashMap所能容纳的最大价值对数量，如果超过则需要扩容，计算方式：threshold=initialCapacity*loadFactor（构造方法中直接通过tableSizeFor(initialCapacity)方法进行了赋值，主要原因是在构造方法中，数组table并没有初始化，put方法中进行初始化，同时put方法中也会对threshold进行重新赋值，这个会在后面的源码中进行分析） loadFactor 加载因子（默认0.75）：当负载因子较大时，去给table数组扩容的可能性就会少，所以相对占用内存较少（空间上较少），但是每条entry链上的元素会相对较多，查询的时间也会增长（时间上较多）。反之就是，负载因子较少的时候，给table数组扩容的可能性就高，那么内存空间占用就多，但是entry链上的元素就会相对较少，查出的时间也会减少。所以才有了负载因子是时间和空间上的一种折中的说法。所以设置负载因子的时候要考虑自己追求的是时间还是空间上的少。（一般情况下不需要设置，系统给的默认值已经比较适合了）
我们最常使用的是无参构造，在这个构造方法里面仅仅设置了加载因子为默认值，其他两个参数会在resize方法里面进行初始化，在这里知道这个结论就可以了，下面会在源码里面进行分析； 另外一个带有两个参数的构造方法，里面对初始容量和阈值进行了初始化，对阈值的初始化方法为 tableSizeFor(int cap) put方法 table尚未初始化 get方法，查找 取模运算 (n - 1) &amp;amp; hash remove方法，删除 其他源码 到这里，hashMap的源码基本就解析完成了，其余的方法和源码逻辑相对非常简单，大部分还是使用上述代码来实现的，例如containsKey（jey），就是使用get方法中的getNode（）来判断的，由于篇幅原因就不一一介绍。 另外，中间有很部分不影响逻辑理解的代码被一笔带过，比如 红黑树的转化，查找，删除等操作，有兴趣的可以自己进行学习，不过还有一些其他的特性需要提醒一下 最后总结一下：
HashMap 底层数据结构在JDK1.7之前是由数组+链表组成的，1.8之后又加入了红黑树；链表长度小于8的时候，发生Hash冲突后会增加链表的长度，当链表长度大于8的时候，会先判读数组的容量，如果容量小于64会先扩容（原因是数组容量越小，越容易发生碰撞，因此当容量过小的时候，首先要考虑的是扩容），如果容量大于64，则会将链表转化成红黑树以提升效率 hashMap 的容量是2的n次幂，无论在初始化的时候传入的初始容量是多少，最终都会转化成2的n次幂，这样做的原因是为了在取模运算的时候可以使用&amp;amp;运算符，而不是%取余，可以极大的提上效率，同时也降低hash冲突 HashMap是非线程安全的，在多线程的操作下会存在异常情况（如形成闭环（1.7），1.8已修复闭环问题，但仍不安全），可以使用HashTable或者ConcurrentHashMap进行代替</description>
    </item>
    
    <item>
      <title>第二篇博客</title>
      <link>http://lionlihuang.github.io/posts/%E7%AC%AC%E4%BA%8C%E7%AF%87%E5%8D%9A%E5%AE%A2/</link>
      <pubDate>Wed, 27 May 2020 14:52:05 +0800</pubDate>
      
      <guid>http://lionlihuang.github.io/posts/%E7%AC%AC%E4%BA%8C%E7%AF%87%E5%8D%9A%E5%AE%A2/</guid>
      <description>多线程基本原理 以前我认为多线程的作用就是提升性能。实际上，多线程并不一定能提升性能（甚至还会降低性能）；多线程也不只是为了提升性能。多线程主要有以下的应用场景： 1、避免阻塞（异步调用） 单个线程中的程序，是顺序执行的。如果前面的操作发生了阻塞，那么就会影响到后面的操作。这时候可以采用多线程，我感觉就等于是异步调用。这样的例子有很多： ajax调用，就是浏览器会启一个新的线程，不阻塞当前页面的正常操作； 流程在某个环节调用web service，如果是同步调用，则需要等待web service调用结果，可以启动新线程来调用，不影响主流程； android里，不要在ui thread里执行耗时操作，否则容易引发ANR； 创建工单时，需要级联往其他表中插入数据，可以将级联插入的动作放到新线程中，先返回工单创建的结果…… 2、避免CPU空转 以http server为例，如果只用单线程响应HTTP请求，即处理完一条请求，再处理下一条请求的话，CPU会存在大量的闲置时间 因为处理一条请求，经常涉及到RPC、数据库访问、磁盘IO等操作，这些操作的速度比CPU慢很多，而在等待这些响应的时候，CPU却不能去处理新的请求，因此http server的性能就很差 所以很多web容器，都采用对每个请求创建新线程来响应的方式实现，这样在等待请求A的IO操作的等待时间里，就可以去继续处理请求B，对并发的响应性就好了很多 当然，这种设计方式并不是绝对的，现在像node.js、Nginx等新一代http server，采用了事件驱动的实现方式，用单线程来响应多个请求也是没问题的。甚至实现了更高的性能，因为多线程是一把双刃剑，在提升了响应性的同时，创建销毁线程都是需要开销的，另外CPU在线程之间切换，也会带来额外的开销。避免了这些额外开销，可能是node.js等http server性能优秀的原因之一吧 3、提升性能 在满足条件的前提下，多线程确实能提升性能 打一个比方，多线程就相当于，把要炒的菜放到了不同的锅里，然后用不同的炉来炒，当然速度会比较快。本来需要先炒西红柿，10分钟；再炒白菜10分钟；加起来就需要20分钟。用了多线程以后，分别放在2个锅里炒，10分钟就都炒好了 基本上，需要满足3个条件： 第1，任务具有并发性，也就是可以拆分成多个子任务。并不是什么任务都能拆分的，条件还比较苛刻 子任务之间不能有先后顺序的依赖，必须是允许并行的 比如 Java代码 a = b + c d = e + f 这个是可以并行的； Java代码 a = b + c d = a + e 这个就无法并行了，第2步计算需要依赖第1步的计算结果，即使分成2个线程，也不会带来任何性能提升 另外，还不能有资源竞争。比如2个线程都需要写一个文件，第1个线程将文件锁定了，第2个线程只能等着，这样的2个子任务，也不具备并发性；执行sychronized代码，也是同样的情况 第2，只有在CPU是性能瓶颈的情况下，多线程才能实现提升性能的目的。比如一段程序，瓶颈在于IO操作，那么把这个程序拆分到2个线程中执行，也是无法提升性能的 第3，有点像废话，就是需要有多核CPU才行。否则的话，虽然拆分成了多个可并行的子任务，但是没有足够的CPU，还是只有一个CPU在多个线程中切换来切换去，不但达不到提升性能的效果，反而由于增加了额外的开销，而降低了性能。类似于虽然把菜放到了2个锅里，但是只有1个炉子一样 如果上述条件都满足，有一个经验公式可以计算性能提升的比例，叫阿姆达尔定律： 速度提升比例 = 1/[(1-P)+(P/N)]，其中P是可并行任务的比例，N是CPU核心数量 假设CPU核心是无限的，则公式简化为1/(1-P) 假设P达到了80%（已经非常高了），那么速度提升比例也只能达到5倍而已 —</description>
    </item>
    
    <item>
      <title>开博大吉</title>
      <link>http://lionlihuang.github.io/posts/%E5%BC%80%E5%8D%9A%E5%A4%A7%E5%90%89/</link>
      <pubDate>Mon, 25 May 2020 13:29:58 +0800</pubDate>
      
      <guid>http://lionlihuang.github.io/posts/%E5%BC%80%E5%8D%9A%E5%A4%A7%E5%90%89/</guid>
      <description>大家好 我的博客已经开通,谢谢大家观赏</description>
    </item>
    
  </channel>
</rss>